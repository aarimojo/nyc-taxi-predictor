{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data\n",
    "processed_data_path = \"../data/processed/yellow_processed_2022_05.parquet\"\n",
    "cleaned_df = pd.read_parquet(processed_data_path)\n",
    "\n",
    "# Visualize the data\n",
    "# Distribution of trip distance\n",
    "sns.histplot(cleaned_df['trip_distance'], kde=True, bins=30)\n",
    "plt.title(\"Distribution of Trip Distance\")\n",
    "plt.xlabel(\"Trip Distance (miles)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Distribution of fare amount\n",
    "if 'fare_amount' in cleaned_df.columns:\n",
    "    sns.histplot(cleaned_df['fare_amount'], kde=True, bins=30)\n",
    "    plt.title(\"Distribution of Fare Amount\")\n",
    "    plt.xlabel(\"Fare Amount ($)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "numeric_df = cleaned_df.select_dtypes(include=['number'])\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(numeric_df.corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['trip_duration', 'fare_amount']\n",
    "features = ['trip_distance', 'store_and_fwd_flag', 'Borough_pu', 'Zone_pu', 'service_zone_pu',\n",
    "       'Borough_do', 'Zone_do', 'service_zone_do', 'day_of_week_pu',\n",
    "       'hour_of_day_pu', 'time_of_day_pu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = cleaned_df[features]\n",
    "y = cleaned_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['store_and_fwd_flag', 'Borough_pu', 'Zone_pu', 'service_zone_pu',\n",
    "       'Borough_do', 'Zone_do', 'service_zone_do', 'time_of_day_pu']\n",
    "numerical_features = ['trip_distance', 'day_of_week_pu', 'hour_of_day_pu', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "numerical_transformer = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "print(X_train.shape)\n",
    "# Entrenar el modelo con seguimiento del progreso\n",
    "best_mse = float('inf')\n",
    "n_steps = 10\n",
    "print(\"Entrenando Decision Tree...\")\n",
    "for i in range(1, X_train.shape[0] + 1):\n",
    "    dt_model.fit(X_train[:i], y_train[:i])  # Ajuste incremental\n",
    "    y_partial_pred = dt_model.predict(X_test)\n",
    "    mse_partial = mean_squared_error(y_test, y_partial_pred)\n",
    "    if mse_partial < best_mse:\n",
    "        best_mse = mse_partial  # Actualiza el mejor MSE encontrado\n",
    "    sys.stdout.write(f\"\\rIteración {i}/{X_train.shape[0]}: MSE parcial = {mse_partial:.4f}, Mejor MSE = {best_mse:.4f}\")  # Sobrescribe la línea anterior\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# Evaluar el modelo final\n",
    "y_pred = dt_model.predict(X_test)  # Genera predicciones en el conjunto de prueba.\n",
    "mse = mean_squared_error(y_test, y_pred)  # Calcula el error cuadrático medio.\n",
    "r2 = r2_score(y_test, y_pred)  # Calcula el coeficiente de determinación R^2.\n",
    "print(f\"Error cuadrático medio (MSE): {mse:.4f}\")  # Imprime el MSE.\n",
    "print(f\"Coeficiente de determinación (R^2): {r2:.4f}\")  # Imprime el R^2.\n",
    "\n",
    "# Importancia de las características\n",
    "feature_importances = pd.DataFrame(\n",
    "    dt_model.feature_importances_,  # Obtiene la importancia de cada característica.\n",
    "    index=X.columns,  # Usa los nombres de las columnas como índice.\n",
    "    columns=['Importancia']  # Define el nombre de la columna de importancia.\n",
    ").sort_values(by='Importancia', ascending=False)  # Ordena las características por importancia en orden descendente.\n",
    "\n",
    "print(\"\\nImportancia de las características:\")\n",
    "print(feature_importances)  # Imprime la tabla de importancias de características."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfinal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
